{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.2654443477959131\n",
      "Epoch 2000, Loss: 0.048873023253222174\n",
      "Epoch 4000, Loss: 0.04846536280818988\n",
      "Epoch 6000, Loss: 0.0475490725930081\n",
      "Epoch 8000, Loss: 0.04385474057571917\n",
      "Epoch 10000, Loss: 0.03456959286286434\n",
      "Epoch 12000, Loss: 0.0031582947958326262\n",
      "Epoch 14000, Loss: 0.0008426095293565533\n",
      "Epoch 16000, Loss: 0.00044584635703624954\n",
      "Epoch 18000, Loss: 0.00029431473419311223\n",
      "Epoch 20000, Loss: 0.00021643310735255182\n",
      "Epoch 22000, Loss: 0.00016963616913590637\n",
      "Epoch 24000, Loss: 0.00013866091625235727\n",
      "Epoch 26000, Loss: 0.00011676203623256417\n",
      "Epoch 28000, Loss: 0.00010052247633746902\n",
      "Epoch 30000, Loss: 8.80354197699716e-05\n",
      "Epoch 32000, Loss: 7.815698864812526e-05\n",
      "Epoch 34000, Loss: 7.016129813452885e-05\n",
      "Epoch 36000, Loss: 6.356651296539773e-05\n",
      "Epoch 38000, Loss: 5.804078886477124e-05\n",
      "최종 결과:\n",
      "[[0.00518249]\n",
      " [0.00686263]\n",
      " [0.00623141]\n",
      " [0.0042002 ]\n",
      " [0.00986014]\n",
      " [0.01316285]\n",
      " [0.00247264]\n",
      " [0.00810353]\n",
      " [0.97791874]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Multi_Layer_Neural_Network:\n",
    "    def __init__(self, input_node, hidden_nodes, output_node):\n",
    "        self.input_node = input_node\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_node = output_node\n",
    "        #hidden 층 weight 설정\n",
    "        self.weights = [np.random.randn(input_node, hidden_nodes[0])]\n",
    "        self.weights += [np.random.randn(hidden_nodes[i], hidden_nodes[i+1]) for i in range(len(hidden_nodes) - 1)]\n",
    "        #output 층 weight 설정\n",
    "        self.weights.append(np.random.randn(hidden_nodes[-1], output_node))\n",
    "        #hidden 층 bias 설정\n",
    "        self.biases = [np.zeros((1, hidden_node)) for hidden_node in hidden_nodes]\n",
    "        #output 층 bias 설정\n",
    "        self.biases.append(np.zeros((1, output_node)))\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #초기에는 x\n",
    "        input = [x]\n",
    "        for i in range(len(self.hidden_nodes) + 1):\n",
    "            layer_input = np.dot(input[i], self.weights[i]) + self.biases[i]\n",
    "            layer_output = self.sigmoid(layer_input)\n",
    "            input.append(layer_output)\n",
    "        return input\n",
    "\n",
    "    def train(self, x, y, learning_rate, num_iters):\n",
    "        \n",
    "        for iter in range(num_iters):\n",
    "            activations = self.forward(x)\n",
    "            #output 값 forward로 구할 수 있음\n",
    "            output_layer_output = activations[-1]\n",
    "            loss = np.mean(0.5 * (y - output_layer_output) ** 2)\n",
    "            \n",
    "\n",
    "            # Backpropagation\n",
    "            #델타 값 저장\n",
    "            deltas = [None] * (len(self.hidden_nodes) + 1)\n",
    "            #델타 마지막 값부터 구하는데 마지막 델타 값은 바로 구할 수 있음\n",
    "            deltas[-1] = (y - output_layer_output) * self.sigmoid_derivative(output_layer_output)\n",
    "\n",
    "            for i in reversed(range(len(self.hidden_nodes))):\n",
    "                #hidden층 델타 값들\n",
    "                deltas[i] = deltas[i+1].dot(self.weights[i+1].T) * self.sigmoid_derivative(activations[i+1])\n",
    "\n",
    "            for i in range(len(self.hidden_nodes) + 1):\n",
    "                #가중치 및 bias 조정\n",
    "                self.weights[i] += activations[i].T.dot(deltas[i]) * learning_rate\n",
    "                self.biases[i] += np.sum(deltas[i], axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "            if iter % 2000 == 0:\n",
    "                print(\"Epoch {0}, Loss: {1}\".format(iter,loss))\n",
    "\n",
    "# 입력 데이터와 레이블\n",
    "train_set_x = np.array([[0, 0], [0, 1], [1, 0], [1, 1], [0.5, 1], [1, 0.5], [0, 0.5], [0.5, 0], [0.5, 0.5]])\n",
    "train_set_y = np.array([[0], [0], [0], [0], [0], [0], [0], [0], [1]])\n",
    "\n",
    "# 다층 신경망 모델 생성\n",
    "Donut_model = Multi_Layer_Neural_Network(input_node=2, hidden_nodes=[4, 4], output_node=1)\n",
    "\n",
    "# 학습\n",
    "learning_rate = 0.1\n",
    "num_epochs = 40000\n",
    "Donut_model.train(train_set_x, train_set_y, learning_rate, num_epochs)\n",
    "\n",
    "# 최종 예측\n",
    "predictions = Donut_model.forward(train_set_x)[-1]\n",
    "print(\"최종 결과:\")\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
